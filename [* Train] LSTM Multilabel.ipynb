{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import gensim\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tnrange\n",
    "from tgraph import plot_loss\n",
    "from IPython.display import clear_output\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "modelwv = Doc2Vec.load(\"./model/doc2vec_before_train.wv\")\n",
    "#embedding = from_pretrained(weights)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "----\n",
    "\n",
    "Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userLog = pd.read_csv(\"./clean_data/userlog_feature.csv\").head(100000)\n",
    "df['datetime'] = pd.to_datetime(df['year'].astype(str)+\"-\"+ df['month'].astype(str) +\"-\"+ df['day'].astype(str)+\" \"+ df['hour'].astype(str)+\":00:00\")\n",
    "df.drop(collum)\n",
    "isTrain = userLog['datetime']<datetime.datetime(2018,2,18)\n",
    "test = userLog[~isTrain]\n",
    "userLog = userLog[isTrain]\n",
    "userLog1 = userLog.sort_values(\"datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userLog.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove user that clicked too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userClickCount = userLog1.groupby(\"userCode\")['project_id'].transform(lambda x: len(x))\n",
    "userLog1['userClickCount'] = userClickCount\n",
    "userLog2 = userLog1[userLog1['userClickCount']<500]\n",
    "# (userLog2['userCode'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get only projects that has more than x user clicked\n",
    "\n",
    "----\n",
    "\n",
    " Our assumption is that we more user click menas the project is better. (And are most likely will be clicked in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_clicked = userLog2.groupby(\"project_id\")['userCode'].transform(lambda x: len(x))\n",
    "userLog2['project_clicked'] = project_id_clicked\n",
    "# (userLog['project_id'].value_counts() <10).sum() to find number of project less than ten clicked\n",
    "userLog3 = userLog2[userLog2['project_clicked']>300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# What projects has this user been clicked.\n",
    "userLogSeq = userLog3.groupby(\"userCode\").agg({\"project_id\":lambda x: list(x)})\n",
    "#userLogSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out filter that we only click once in this database. (We'll use them later.)\n",
    "userLogSeqFiltered = userLogSeq[userLogSeq['project_id'].apply(lambda x: len(x))>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map project id to project Index [0 to index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelwv.wv.index2word.index('6709')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userLogSeqFiltered2 = userLogSeqFiltered\n",
    "userLogSeqFiltered2['project_id'] = userLogSeqFiltered['project_id'].apply(lambda x: [modelwv.wv.index2word.index(str(i)) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data format\n",
    "[12, 14, 15, 17, 14, 17, 12], -> [12,14,15,16,14,17] : [14, 15, 17, 14, 17, 12]\n",
    "\"\"\"\n",
    "userLogSeqFiltered2['features'] = userLogSeqFiltered2['project_id'].apply(lambda x: x[:-1])\n",
    "userLogSeqFiltered2['targets'] = userLogSeqFiltered2['project_id'].apply(lambda x: x[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare into pad pack sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad and save length as function\n",
    "userLogSeqFiltered3 = userLogSeqFiltered2\n",
    "userLogSeqFiltered3['seq_len'] = userLogSeqFiltered3['features'].apply(len)\n",
    "userSeq = userLogSeqFiltered3.sort_values('seq_len',ascending=False)[userLogSeqFiltered3['seq_len']<500] # Best should be 5k?\n",
    "maxSeq = max(userSeq['seq_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with 0\n",
    "userSeq['padded_features'] = userSeq.apply(lambda x: x['features']+[0]*(maxSeq - x['seq_len']),axis=1)\n",
    "userSeq['padded_targets'] = userSeq.apply(lambda x: x['targets']+[0]*(maxSeq - x['seq_len']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Variable(torch.Tensor(userSeq['padded_features']).long().cuda())\n",
    "targets = Variable(torch.Tensor(userSeq['padded_targets'])).long().cuda()\n",
    "seq_len = torch.Tensor(userSeq['seq_len'].values).long().cuda()\n",
    "\n",
    "print(features.shape)\n",
    "print(targets.shape)\n",
    "print(seq_len.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userSeq['padded_features'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PadPack: (seq_len, ) #ต้องเรียงความยาวแล้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(modelwv.wv.syn0)\n",
    "weights.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_size = 15\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        #self.projEmbedding = nn.Embedding(*weights.shape).from_pretrained(weight) # Spreading tuple into embedding dim\n",
    "        self.projEmbedding = from_pretrained(weights, False)\n",
    "        \n",
    "        self.lstm = nn.LSTM(weights.shape[1],hidden_size, bidirectional = False)\n",
    "        \n",
    "        self.hidden2out = nn.Linear(hidden_size, weights.shape[0])#weights.shape[0])\n",
    "            \n",
    "        \n",
    "        \n",
    "        #self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        #TODO: change to clicking context\n",
    "        self.hidden = (Variable(torch.zeros(1, batch_size, hidden_size).cuda()),Variable(torch.zeros(1, batch_size, hidden_size).cuda()))\n",
    "        \n",
    "    def forward(self, inputs, lengths):\n",
    "\n",
    "        batch_size = inputs.size()[0]\n",
    "        \n",
    "        embeds = self.projEmbedding(inputs)\n",
    "        \n",
    "        transposed_embeds = embeds.transpose(0,1)\n",
    "        \n",
    "        self.init_hidden(batch_size)\n",
    "        \n",
    "        packed_input = pack_padded_sequence(transposed_embeds, lengths.cpu().numpy())\n",
    "        packed_outputs, (ht, ct) = self.lstm(packed_input, self.hidden)\n",
    "        \n",
    "        out, _ = pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        out = self.hidden2out(out)\n",
    "        \n",
    "        return out.transpose(0,1)#out.transpose(0,1)#\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_pretrained(embeddings, freeze=True):\n",
    "    assert embeddings.dim() == 2, \\\n",
    "         'Embeddings parameter is expected to be 2-dimensional'\n",
    "    rows, cols = embeddings.shape\n",
    "    embedding = torch.nn.Embedding(num_embeddings=rows, embedding_dim=cols)\n",
    "    embedding.weight = torch.nn.Parameter(embeddings)\n",
    "    embedding.weight.requires_grad = not freeze\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test neural networks\n",
    "outputs = model(features[:50], seq_len[:50])\n",
    "# values, indices = torch.max(outputs, 2)\n",
    "# indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "# criterion = nn.MSELoss()\n",
    "#TODO: binary cross entropy\n",
    "def loss_function(outputs,targets):    \n",
    "    bs, seq_len, _ = outputs.size()\n",
    "    \n",
    "    targets = targets[:,:seq_len]\n",
    "    \n",
    "    outputs_spread = outputs.contiguous().view(-1,weights.shape[0]).squeeze(1)\n",
    "    targets_spread = targets.contiguous().view(-1,1).squeeze(1)\n",
    "        \n",
    "    return criterion(outputs_spread, targets_spread)\n",
    "\n",
    "print(loss_function(outputs,targets[:50]))\n",
    "\n",
    "# The project embedding were freezed\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(features[:5], seq_len[:5])\n",
    "loss = loss_function(outputs,targets[:5])\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "trainIdx = int(features.shape[0]*train_ratio)\n",
    "X_train, X_test = features[:trainIdx], features[trainIdx:]\n",
    "y_train, y_test = targets[:trainIdx], targets[trainIdx:]\n",
    "seq_train, seq_test = seq_len[:trainIdx], seq_len[trainIdx:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import bokeh\n",
    "import pandas as pd\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "output_notebook(bokeh.resources.INLINE)\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_loss(score_record):\n",
    "    df = pd.DataFrame(score_record,columns=[\"train_loss\",\"test_loss\",\"MAP\",\"batch\",\"epoch\",\"batch_size\"])\n",
    "    df['avg_loss'] = df.groupby(\"epoch\")['train_loss'].transform(\"mean\")\n",
    "    df['avg_eval_loss'] = df.groupby(\"epoch\")['test_loss'].transform(\"mean\")\n",
    "    df['avg_MAP'] = df.groupby(\"epoch\")['MAP'].transform(\"mean\")\n",
    "\n",
    "    # create a new plot with a title and axis labels\n",
    "    p = figure(title=\"Loss graph [epoch: %d]\"%(df['epoch'].max()), x_axis_label='Time', y_axis_label='Loss')\n",
    "\n",
    "    # add a line renderer with legend and line thickness\n",
    "    p.line(df.index, df['train_loss'], legend=\"Train Loss.\",  line_width=1, color=\"orange\")\n",
    "\n",
    "    p.line(df.index, df['avg_loss'], legend=\"Train Avg Loss.\", line_width=4, color=\"red\")\n",
    "    \n",
    "      # add a line renderer with legend and line thickness\n",
    "    p.line(df.index, df['test_loss'], legend=\"Test Loss.\",  line_width=1 )\n",
    "\n",
    "    p.line(df.index, df['avg_eval_loss'], legend=\"Test Avg Loss.\", line_width=4, color=\"green\")\n",
    "    \n",
    "    p.line(df.index, df['MAP'], legend=\"MAP@7\",  line_width=1, color=\"black\")\n",
    "    \n",
    "    p.legend.click_policy=\"hide\"\n",
    "    # show the results\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "score_record = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training \n",
    "import math\n",
    "\n",
    "batch_size = 64\n",
    "batch_per_epoch = math.ceil(X_train.shape[0]/batch_size)\n",
    "epoch_num = 100\n",
    "\n",
    "\n",
    "for epoch in tnrange(epoch,epoch_num):\n",
    "    for batch_iter in tnrange(batch_per_epoch):\n",
    "        start, end = batch_iter*batch_size, (batch_iter+1)* batch_size\n",
    "        X_training_batch, y_training_batch, seq_training_batch  = X_train[start:end], y_train[start:end], seq_train[start:end]\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_training_batch, seq_training_batch)\n",
    "        loss = loss_function(outputs, y_training_batch)\n",
    "        \n",
    "        eval_outputs = model(X_test, seq_test)\n",
    "        eval_loss = loss_function(eval_outputs, y_test)\n",
    "        \n",
    "        MAP_score, _  = calMap(model)\n",
    "        print(MAP_score)\n",
    "        #MAP_score = 0\n",
    "        score_record.append((loss.data[0],eval_loss.data[0],MAP_score,batch_iter,epoch,batch_size))    \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    clear_output()\n",
    "    plot_loss(score_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO extract most probably correct projects from deep\n",
    "def score_AP(correct, recommended, n=7):\n",
    "    recommended = list(recommended)[:7]\n",
    "    assert(len(set(recommended))==len(recommended)) # Recommended should be unique    \n",
    "    precisions = []\n",
    "    correct_score = 1\n",
    "    for idx, recommend_item in enumerate(recommended):\n",
    "        if str(recommend_item) not in correct: precisions.append(0)\n",
    "        else:                         \n",
    "            precisions.append(correct_score/(idx+1))\n",
    "            correct_score+=1\n",
    "    return sum(precisions)/min(len(correct),n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_userLog = pd.read_csv(\"./clean_data/deeplstmfeatures.csv\")\n",
    "test_padded_features =  test_userLog['padded_features'].apply(lambda x: eval(x))\n",
    "test_userLog['ans_project_id'] = test_userLog['ans_project_id'].apply(lambda x: eval(x))\n",
    "test_userLog['ans_project_id'] = test_userLog['ans_project_id'].apply(lambda x: [modelwv.wv.index2word.index(str(i)) for i in x if str(i) in modelwv.wv.index2word])\n",
    "test_userLog = test_userLog[test_userLog['ans_project_id'].apply(lambda x: len(x)>0)]\n",
    "test_seq_len = test_userLog['seq_len'].values\n",
    "\n",
    "#filtered_submission_users = userLog[ans_project_id.apply(len) > 0].set_index(\"userCode\")\n",
    "\n",
    "\n",
    "test_features_tensor = Variable(torch.Tensor(test_padded_features).long()).cuda()\n",
    "test_seq_len_tensor = torch.Tensor(test_seq_len).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calMap(model, n = 10):\n",
    "    outputs = model(test_features_tensor[:n], test_seq_len_tensor[:n]).cpu()\n",
    "    preds = np.array([o[seq-1].data.numpy() for o, seq in zip(outputs,test_seq_len[:n])])\n",
    "    idxes = [(-preds[1]).argsort()[:30] for pred in preds]\n",
    "    testingUser = test_userLog.head(n)\n",
    "    testingUser['preds'] = idxes\n",
    "    #print(testingUser['preds'])\n",
    "    testingUser.apply(lambda row: [pred for pred in row['preds'] if pred not in row['ans_project_id']],axis=1)\n",
    "    testingUser['MAP'] = testingUser.apply(lambda x: score_AP(x['ans_project_id'],x['preds']),axis=1)\n",
    "    return testingUser['MAP'].mean(),testingUser\n",
    "score, df = calMap(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model/LSTMfuture_v4.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
