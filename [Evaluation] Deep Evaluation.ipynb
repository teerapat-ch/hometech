{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"./model/IdxDov2VecDeep_v5_7epoch.weight\"\n",
    "#testing_user = \"./data/testing_users.csv\"\n",
    "testing_user = \"./clean_data/test_data/test_before_021718_7000row_fold0.csv\"\n",
    "submission_file = \"./submission/deep_learning_v5.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting projects for user using deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all necessary data frame here\n",
    "submission_users = pd.read_csv(testing_user)\n",
    "userLog = pd.read_csv('./clean_data/userLog_beforeTest.csv')\n",
    "item_feature = pd.read_csv('./clean_data/proj.csv')\n",
    "user_feature = pd.read_csv('./clean_data/user_v2.csv')\n",
    "docvec = pd.read_csv(\"./clean_data/doc2vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2IdxDf = pd.read_csv(\"./clean_data/user2Idx.csv\")\n",
    "proj2IdxDf  = pd.read_csv(\"./clean_data/proj2Idx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "userEmbeddingNum = user2IdxDf.shape[0]\n",
    "projEmbeddingNum = proj2IdxDf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "While copying the parameter named userEmbedding.weight, whose dimensions in the model are torch.Size([482744, 100]) and whose dimensions in the checkpoint are torch.Size([482744, 150]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                     \u001b[0mown_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: sizes do not match at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THC/generic/THCTensorCopy.c:101",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1c8babc3c753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    517\u001b[0m                                        \u001b[0;34m'whose dimensions in the model are {} and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                                        \u001b[0;34m'whose dimensions in the checkpoint are {}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                                        .format(name, own_state[name].size(), param.size()))\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 raise KeyError('unexpected key \"{}\" in state_dict'\n",
      "\u001b[0;31mRuntimeError\u001b[0m: While copying the parameter named userEmbedding.weight, whose dimensions in the model are torch.Size([482744, 100]) and whose dimensions in the checkpoint are torch.Size([482744, 150])."
     ]
    }
   ],
   "source": [
    "## Deep Learning Here!\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, doc2vecDim = 300):\n",
    "        super(Net, self).__init__()        \n",
    "        self.doc2VecDim = doc2vecDim        \n",
    "        self.userEmbedding = nn.Embedding(userEmbeddingNum, 100)\n",
    "        self.projEmbedding = nn.Embedding(projEmbeddingNum, 100)        \n",
    "        self.dVecFc= nn.Linear(doc2vecDim, 300)                \n",
    "        self.hidden = nn.Linear(500,300)\n",
    "        self.hidden2 = nn.Linear(300,200)\n",
    "        self.hidden3 = nn.Linear(200,200)\n",
    "        self.fc2 = nn.Linear(200,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        userFeature, projFeature, dVecFeature = x[:,:1],x[:,1:2], x[:,-self.doc2VecDim:]\n",
    "        try:\n",
    "            userEmbedding = self.userEmbedding(userFeature.long())\n",
    "            projEmbedding = self.projEmbedding(projFeature.long())\n",
    "            dVecEmbedding = F.relu(self.dVecFc(dVecFeature))\n",
    "        except e:\n",
    "            print(e)\n",
    "            print(userFeature.max(),projFeature.max())\n",
    "        \n",
    "        combined = torch.cat((userEmbedding.view(len(x),-1), projEmbedding.view(len(x),-1),dVecEmbedding.view(len(x),-1)),dim=1)\n",
    "        x = self.hidden(combined)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each user, select multiple projects that pass some certain condition\n",
    "# Current condition: same province and price range.\n",
    "\"\"\"\n",
    "Log_starting_price, province, (lat_lon distance)\n",
    "\"\"\"\n",
    "#submission_users_merged = submission_users.merge(user_feature,on='userCode')[['Log_starting_price',' province']]#['district_id']#.merge(item_feature,on='project_id')\n",
    "from itertools import product\n",
    "\n",
    "#Unleash hell here (Reload checking_df to be full size)\n",
    "checking_df = pd.DataFrame(list(product(submission_users['userCode'], item_feature['project_id'])),columns=['userCode','project_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 31s, sys: 6min 1s, total: 11min 33s\n",
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Merge the checking dataframe with user feature and item feature\n",
    "checking_df_mergedd = checking_df.merge(user_feature,on='userCode').merge(item_feature, on='project_id',suffixes=(\"_user\",\"_project\")) # Takes 3 mins\n",
    "checking_df_merged = checking_df_mergedd[['userCode','project_id','starting_price_range_user','starting_price_range_project','project_list','most_province_id','province_id_project']] # 50 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_feature[item_feature['project_id']==8997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37653000, 7)\n",
      "(37594070, 7)\n",
      "CPU times: user 24min 44s, sys: 3min 48s, total: 28min 32s\n",
      "Wall time: 28min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Filter out rows that do not statisfied the conditions\n",
    "\n",
    "\n",
    "# samePriceRange = checking_df_merged['starting_price_range_user'] == checking_df_merged['starting_price_range_project']\n",
    "# checking_df_merged_filtered = checking_df_merged[samePriceRange]\n",
    "\n",
    "# sameProvince = checking_df_merged_filtered['province_id_project']==checking_df_merged_filtered['most_province_id']\n",
    "# checking_df_merged_filtered = checking_df_merged_filtered[sameProvince]\n",
    "\n",
    "checking_df_merged_filtered = checking_df_merged\n",
    "\n",
    "print(checking_df_merged_filtered.shape)\n",
    "# Filter out rows that with project that user has already seen\n",
    "hasOldProject = checking_df_merged_filtered.apply(lambda row: str(row['project_id']) in row['project_list'],axis=1)\n",
    "checking_df_merged_filtered = checking_df_merged_filtered[~hasOldProject]\n",
    "\n",
    "print(checking_df_merged_filtered.shape)soundex\n",
    "checking_df_merged_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37594070 entries, 0 to 37652999\n",
      "Data columns (total 7 columns):\n",
      "userCode                        object\n",
      "project_id                      int64\n",
      "starting_price_range_user       float64\n",
      "starting_price_range_project    int64\n",
      "project_list                    object\n",
      "most_province_id                int64\n",
      "province_id_project             int64\n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "checking_df_merged_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_df_merged_filtered.to_csv(\"./clean_data/deep_features_7000k.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue here\n",
    "checking_df_merged_filtered = pd.read_csv(\"./clean_data/deep_features_7000k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "\n",
    "#1. Only select userCode and project_id\n",
    "checking_df_fin = checking_df_merged_filtered[['userCode','project_id']]\n",
    "\n",
    "\n",
    "#2. Map userCode and project_id to its Idx\n",
    "checking_df_fet = checking_df_fin.merge(user2IdxDf[['userCode','userIdx']], on = 'userCode',suffixes=(\"\",\"_user\"))\n",
    "checking_df_fet = checking_df_fet.merge(proj2IdxDf[['project_id','projIdx']], on = 'project_id',suffixes=(\"_user\",\"_project\"))\n",
    "\n",
    "#3. Concat doc2vec vector by project_id\n",
    "checking_df_fet3 = checking_df_fet.merge(docvec, on='project_id')\n",
    "\n",
    "\n",
    "checking_df_fet2 = checking_df_fet3.drop(columns=['userCode','project_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking_df_fet3.to_csv(\"./clean_data/deep_test_7000row_fold0.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = checking_df_fet2.fillna(0)\n",
    "test_tensors = Variable(torch.Tensor(test.values).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predicting with model\n",
    "outputs = model(test_tensors).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_df_fet3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top n scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Rank each user based on their project score\n",
    "\n",
    "ranking_df = checking_df_fet[['userCode','project_id']]\n",
    "ranking_df['scores'] = outputs\n",
    "ranking_df['rank'] = ranking_df.groupby('userCode')['scores'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only first seven, then combine them into list (In order!)\n",
    "selected_ranking_df = ranking_df[ranking_df['rank']<=7]\n",
    "user_answered_projects = selected_ranking_df.sort_values([\"userCode\",'rank']).groupby(\"userCode\").agg({\"project_id\":lambda x:list(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_projects = [5858, 3738, 4201, 5452, 5678, 5764, 5067]\n",
    "def fillProject(project_ids):\n",
    "    \n",
    "    if len(project_ids)>=7: return \" \".join([str(i) for i in project_ids])\n",
    "    else: \n",
    "        project_ids.extend(def_projects[:7-len(project_ids)])\n",
    "        return \" \".join([str(i) for i in project_ids])\n",
    "    \n",
    "fillProject([4743, 6720, 5286, 6727, 8847, 6624])    \n",
    "\n",
    "user_complete_answered = user_answered_projects\n",
    "user_complete_answered['project_id'] = user_complete_answered['project_id'].apply(fillProject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge testing users with the dataframe, if user doesn't have their ranking, set to default project value.\n",
    "user_complete_answered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = submission_users.merge(user_complete_answered, on='userCode')\n",
    "ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv(submission_file,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
